{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression in Machine Learning\n",
    "\n",
    "Linear regression is a statistical method used to examine the relationship between a dependent variable (also called the response or outcome variable) and one or more independent variables (also called predictor or explanatory variables).\n",
    "\n",
    "A linear regression model assumes that there is a linear relationship between the dependent variable and the independent variables. That is, it assumes that a change in the independent variables will result in a proportional change in the dependent variable.\n",
    "\n",
    "**Example:** predicting housing prices based on features such as the number of bedrooms, square footage, and location.\n",
    "\n",
    "<img src=\"ML-image/Linear-reg1.png\" width=\"350\" height=\"300\" />\n",
    "\n",
    "Mathematically, we can represent a linear regression as:\n",
    "\n",
    "$y=\\beta_0+ \\beta_1 x + \\epsilon$\n",
    "\n",
    "where\n",
    "\n",
    "- $y$= Dependent Variable (Target Variable)\n",
    "- $x$= Independent Variable (predictor Variable)\n",
    "- $\\beta_0$= intercept of the line (Gives an additional degree of freedom)\n",
    "- $\\beta_1$ = Linear regression coefficient (scale factor to each input value).\n",
    "- $\\epsilon$ = random error\n",
    "\n",
    "The goal of linear regression is to estimate the values of the regression coefficients \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Linear Regression\n",
    "\n",
    "Linear regression can be further divided into two types of the algorithm:\n",
    "\n",
    "1. **Simple Linear Regression:** If a single independent variable is used to predict the value of a numerical dependent variable, then such a Linear Regression algorithm is called Simple Linear Regression.\n",
    "2. **Multiple Linear regression:** If more than one independent variable is used to predict the value of a numerical dependent variable, then such a Linear Regression algorithm is called Multiple Linear Regression.\n",
    "\n",
    "### Relationship of regression lines\n",
    "\n",
    "- A linear line showing the relationship between the dependent and independent variables is called a regression line. \n",
    "- A regression line can show two types of relationship:\n",
    "\n",
    "1. **Positive Linear Relationship:** If the dependent variable increases on the Y-axis and independent variable increases on X-axis, then such a relationship is termed as a Positive linear relationship.\n",
    "\n",
    "<img src=\"https://static.javatpoint.com/tutorial/machine-learning/images/linear-regression-in-machine-learning2.png\" width=\"300\" height=\"250\" />\n",
    "\n",
    "2. **Negative Linear Relationship:** If the dependent variable decreases on the Y-axis and independent variable increases on the X-axis, then such a relationship is called a negative linear relationship.\n",
    "\n",
    "<img src=\"https://static.javatpoint.com/tutorial/machine-learning/images/linear-regression-in-machine-learning3.png\" width=\"300\" height=\"250\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Steps in building a regression model\n",
    "\n",
    "- **STEP 1: Collect/Extract Data:** The first step in building a regression model is to collect or extract data on the dependent (outcome) variable and independent (feature) variables from different data sources.\n",
    "\n",
    "- **STEP 2: Pre-Process the Data:** Before the model is built, it is essential to ensure the quality of the data for issues such as reliability, com- pleteness, usefulness, accuracy, missing data, and outliers.\n",
    "    - Data imputation techniques may be used to deal with missing data. Use of descriptive statistics  and visualization (such as box plot and scatter plot) may be used to identify the existence of outliers and variability in the dataset.\n",
    "    - Many new variables (such as the ratio of variables or product of variables) can be derived (aka feature engineering) and also used in model building.\n",
    "    - Categorical data must be pre-processed using dummy variables as a part of feature engineering, prior to utilizing it in a regression model.\n",
    "\n",
    "\n",
    "- **STEP 3: Dividing Data into Training and Validation Datasets:** In this stage the data is divided into two subsets (sometimes more than two subsets): \n",
    "    - training dataset and \n",
    "    - validation or test dataset. \n",
    "    \n",
    "    The proportion of training dataset is usually between 70% and 80% of the data and the remaining data is treated as the validation data. The subsets may be created using random/ stratified sampling procedure. This is an important step to measure the performance of the model using dataset not used in model building. It is also essential to check for any overfitting of the model. In many cases, multiple training and multiple test data are used (called cross-validation).\n",
    "\n",
    "- **STEP 4: Perform Descriptive Analytics or Data Exploration:** It is always a good practice to perform descriptive analytics before moving to building a predictive analytics model. Descriptive statistics will help us to understand the variability in the model and visualization of the data through, say, a box plot which will show if there are any outliers in the data. Another visualization technique, the scatter plot, may also reveal if there is any obvious relationship between the two variables under consideration. Scatter plot is useful to describe the functional relationship between the dependent or outcome variable and features.\n",
    "\n",
    "- **STEP 5: Build the Model:** The model is built using the training dataset to estimate the regression parameters. The method of Ordinary Least Squares (OLS) is used to estimate the regression parameters. \n",
    "\n",
    "- **STEP 6: Perform Model Diagnostics:** Regression is often misused since many times the modeler fails to perform necessary diagnostics tests before applying the model. Before it can be applied, it is necessary that the model created is validated for all model assumptions including the definition of the function form. If the model assumptions are violated, then the modeler must use remedial measure.\n",
    "- **STEP 7: Validate the Model and Measure Model Accuracy:** A major concern in analytics is over-fitting, that is, the model may perform very well on the training dataset, but may perform badly in validation dataset. It is important to ensure that the model perfor- mance is consistent on the validation dataset as is in the training dataset. In fact, the model may be cross- validated using multiple training and test datasets.\n",
    "\n",
    "- **STEP 8: Decide on Model Deployment:** The final step in the regression model is to develop a deployment strategy in the form of actionable items and business rules that can be used by the organization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
